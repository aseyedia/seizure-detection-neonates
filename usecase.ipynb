{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import copy_model, model_DL2\n",
    "from utils import rearrange_epochs\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/disaev/.virtualenvs/dl0/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a model and load weights from pre-training on Duke dataset. Adjust path in WEIGHTS_FILE variable\n",
    "X = np.empty([100,12,256]) #batch size, channel number, samples number\n",
    "Y = np.empty([100,1])\n",
    "model=model_DL2(X,Y)\n",
    "WEIGHTS_FILE='/media/ssd/projects/MLHC_results/models/DL6_Duke_Classbalance_FullDataset/PT130_DL6_Duke_FullDataset_class.model_weights'\n",
    "model.load_weights(WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a model suited for Helsinki dataset and copy weights to it\n",
    "X_helsinki = np.empty([100,18,256])\n",
    "Y_helsinki = np.empty([100,1])\n",
    "model_helsinki = model_DL2(X_helsinki,Y_helsinki)\n",
    "model_helsinki = copy_model(model,model_helsinki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load data of one subject from Helsinki dataset. \n",
    "# Extraction is done via adjusted code from Tapani et al. repository\n",
    "# Seizure annotations are by consensus of 3 raters\n",
    "matdata_fname = 'helsinki_eeg1_feats.mat'\n",
    "annot_fname = 'helsinki_eeg1_cons_chan_annot.mat'\n",
    "matdata = sio.loadmat(matdata_fname)\n",
    "matannot = sio.loadmat(annot_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Transform matdata and matannot into a suitable structure for prediction, and predict\n",
    "# Duke dataset is trained on different scale of the data, so we need to add scaling coefficient sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN epochs: 225\n",
      "correct epochs: 1522\n"
     ]
    }
   ],
   "source": [
    "epochs, annot, _ = rearrange_epochs(matdata['all_feats'], matannot['annot'], 1,\n",
    "                                                      None, n_chan=18)\n",
    "sc = 0.001\n",
    "epochs = epochs*sc\n",
    "pred = model_helsinki.predict(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8993665648077414"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple AUC score with annotations and predictions. Post-processing usually improves this AUC value.\n",
    "roc_auc_score(annot,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
